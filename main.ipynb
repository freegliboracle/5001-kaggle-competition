{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.52112\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'Id' column\n",
    "train_ID = train['id']\n",
    "test_ID = test['id']\n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(\"id\", axis = 1, inplace = True)\n",
    "test.drop(\"id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>n_clusters_per_class</th>\n",
       "      <th>n_informative</th>\n",
       "      <th>flip_y</th>\n",
       "      <th>scale</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "      <td>400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503</td>\n",
       "      <td>0.004</td>\n",
       "      <td>555.510</td>\n",
       "      <td>489.210</td>\n",
       "      <td>2.810</td>\n",
       "      <td>756.210</td>\n",
       "      <td>766.145</td>\n",
       "      <td>5.855</td>\n",
       "      <td>3.458</td>\n",
       "      <td>8.675</td>\n",
       "      <td>0.049</td>\n",
       "      <td>50.339</td>\n",
       "      <td>3.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.004</td>\n",
       "      <td>265.000</td>\n",
       "      <td>287.456</td>\n",
       "      <td>2.951</td>\n",
       "      <td>373.326</td>\n",
       "      <td>375.214</td>\n",
       "      <td>2.493</td>\n",
       "      <td>1.101</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.030</td>\n",
       "      <td>28.993</td>\n",
       "      <td>5.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>103.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>110.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.528</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>333.250</td>\n",
       "      <td>232.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>451.500</td>\n",
       "      <td>439.750</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>25.230</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.492</td>\n",
       "      <td>0.001</td>\n",
       "      <td>532.000</td>\n",
       "      <td>499.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>748.000</td>\n",
       "      <td>774.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>51.630</td>\n",
       "      <td>1.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.010</td>\n",
       "      <td>787.250</td>\n",
       "      <td>728.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1065.750</td>\n",
       "      <td>1088.500</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>74.948</td>\n",
       "      <td>3.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.010</td>\n",
       "      <td>998.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1397.000</td>\n",
       "      <td>1397.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>99.748</td>\n",
       "      <td>41.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       l1_ratio   alpha  max_iter  random_state  n_jobs  n_samples  \\\n",
       "count   400.000 400.000   400.000       400.000 400.000    400.000   \n",
       "mean      0.503   0.004   555.510       489.210   2.810    756.210   \n",
       "std       0.232   0.004   265.000       287.456   2.951    373.326   \n",
       "min       0.100   0.000   103.000         0.000  -1.000    100.000   \n",
       "25%       0.300   0.000   333.250       232.250   1.000    451.500   \n",
       "50%       0.492   0.001   532.000       499.000   2.000    748.000   \n",
       "75%       0.704   0.010   787.250       728.000   4.000   1065.750   \n",
       "max       0.895   0.010   998.000      1000.000   8.000   1397.000   \n",
       "\n",
       "       n_features  n_classes  n_clusters_per_class  n_informative  flip_y  \\\n",
       "count     400.000    400.000               400.000        400.000 400.000   \n",
       "mean      766.145      5.855                 3.458          8.675   0.049   \n",
       "std       375.214      2.493                 1.101          1.522   0.030   \n",
       "min       110.000      2.000                 2.000          5.000   0.000   \n",
       "25%       439.750      4.000                 3.000          8.000   0.021   \n",
       "50%       774.000      6.000                 3.000          9.000   0.047   \n",
       "75%      1088.500      8.000                 4.000         10.000   0.075   \n",
       "max      1397.000     10.000                 5.000         12.000   0.100   \n",
       "\n",
       "        scale    time  \n",
       "count 400.000 400.000  \n",
       "mean   50.339   3.202  \n",
       "std    28.993   5.266  \n",
       "min     1.528   0.075  \n",
       "25%    25.230   0.504  \n",
       "50%    51.630   1.405  \n",
       "75%    74.948   3.629  \n",
       "max    99.748  41.100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>alpha</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>n_clusters_per_class</th>\n",
       "      <th>n_informative</th>\n",
       "      <th>flip_y</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.513</td>\n",
       "      <td>0.003</td>\n",
       "      <td>510.740</td>\n",
       "      <td>487.260</td>\n",
       "      <td>5.030</td>\n",
       "      <td>1055.130</td>\n",
       "      <td>1086.700</td>\n",
       "      <td>6.130</td>\n",
       "      <td>3.370</td>\n",
       "      <td>8.580</td>\n",
       "      <td>0.052</td>\n",
       "      <td>50.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.227</td>\n",
       "      <td>0.004</td>\n",
       "      <td>251.590</td>\n",
       "      <td>296.587</td>\n",
       "      <td>5.595</td>\n",
       "      <td>579.634</td>\n",
       "      <td>525.249</td>\n",
       "      <td>2.501</td>\n",
       "      <td>1.134</td>\n",
       "      <td>1.742</td>\n",
       "      <td>0.029</td>\n",
       "      <td>25.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>116.000</td>\n",
       "      <td>148.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348</td>\n",
       "      <td>0.000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>237.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>524.250</td>\n",
       "      <td>655.250</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>27.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.001</td>\n",
       "      <td>486.000</td>\n",
       "      <td>478.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1028.500</td>\n",
       "      <td>1117.500</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>55.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.010</td>\n",
       "      <td>728.500</td>\n",
       "      <td>765.750</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1589.500</td>\n",
       "      <td>1501.250</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.076</td>\n",
       "      <td>68.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.010</td>\n",
       "      <td>983.000</td>\n",
       "      <td>977.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>1993.000</td>\n",
       "      <td>1993.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>98.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       l1_ratio   alpha  max_iter  random_state  n_jobs  n_samples  \\\n",
       "count   100.000 100.000   100.000       100.000 100.000    100.000   \n",
       "mean      0.513   0.003   510.740       487.260   5.030   1055.130   \n",
       "std       0.227   0.004   251.590       296.587   5.595    579.634   \n",
       "min       0.109   0.000   104.000         4.000  -1.000    116.000   \n",
       "25%       0.348   0.000   291.000       237.500   1.000    524.250   \n",
       "50%       0.524   0.001   486.000       478.000   4.000   1028.500   \n",
       "75%       0.706   0.010   728.500       765.750   8.000   1589.500   \n",
       "max       0.900   0.010   983.000       977.000  16.000   1993.000   \n",
       "\n",
       "       n_features  n_classes  n_clusters_per_class  n_informative  flip_y  \\\n",
       "count     100.000    100.000               100.000        100.000 100.000   \n",
       "mean     1086.700      6.130                 3.370          8.580   0.052   \n",
       "std       525.249      2.501                 1.134          1.742   0.029   \n",
       "min       148.000      2.000                 2.000          5.000   0.000   \n",
       "25%       655.250      4.000                 2.000          7.000   0.031   \n",
       "50%      1117.500      6.000                 3.000          8.000   0.052   \n",
       "75%      1501.250      8.000                 4.000         10.000   0.076   \n",
       "max      1993.000     10.000                 5.000         12.000   0.100   \n",
       "\n",
       "        scale  \n",
       "count 100.000  \n",
       "mean   50.018  \n",
       "std    25.160  \n",
       "min     2.153  \n",
       "25%    27.698  \n",
       "50%    55.086  \n",
       "75%    68.791  \n",
       "max    98.798  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.time.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (500, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['l1_ratio', 'alpha', 'random_state', 'n_clusters_per_class', \n",
    "               'flip_y','scale'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_data)):\n",
    "    if all_data['n_jobs'][i] == -1: \n",
    "        all_data['n_jobs'][i] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = ('penalty', 'n_classes',  'n_informative', 'n_jobs')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(all_data[c].values)) \n",
    "    all_data[c] = lbl.transform(list(all_data[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (500, 7)\n"
     ]
    }
   ],
   "source": [
    "# shape        \n",
    "print('Shape all_data: {}'.format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_samples</th>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_features</th>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_informative</th>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_classes</th>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skew\n",
       "n_samples     0.395\n",
       "n_features    0.202\n",
       "n_informative 0.117\n",
       "max_iter      0.045\n",
       "n_classes     0.034\n",
       "penalty       0.028\n",
       "n_jobs        0.014"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "y_train = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['max_iter', 'n_classes', 'n_features', 'n_informative', 'n_jobs',\n",
       "       'n_samples', 'penalty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop([''], axis=1, inplace=True)\n",
    "# test.drop([''], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = make_pipeline(RobustScaler(), MLPRegressor(hidden_layer_sizes=(100, 50, 30, 30), activation='tanh', \n",
    "                                                  alpha=0.11, \n",
    "                                                  solver = 'lbfgs',\n",
    "#                                                   learning_rate='adaptive', \n",
    "                                                  max_iter=20000, tol=1e-10))\n",
    "# mlp = make_pipeline(RobustScaler(), MLPRegressor(hidden_layer_sizes=(200, 100, 80, 40, 30), activation='tanh', \n",
    "#                                                  alpha=0.05, max_iter=2000, tol=1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = make_pipeline(RobustScaler(), MLPRegressor(hidden_layer_sizes=(100, 50, 30, 30), activation='tanh', \n",
    "                                                  alpha=0.115, \n",
    "                                                  solver = 'lbfgs',\n",
    "#                                                   learning_rate='adaptive', \n",
    "                                                  max_iter=20000, tol=1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3 = make_pipeline(RobustScaler(), MLPRegressor(hidden_layer_sizes=(100, 50, 30, 30), activation='tanh', \n",
    "                                                  alpha=0.11, \n",
    "                                                  solver = 'lbfgs',\n",
    "#                                                   learning_rate='adaptive', \n",
    "                                                  max_iter=20000, tol=1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5,\n",
    "                                  tol=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.0729 (0.0075)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(mlp1)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.0746 (0.0080)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(mlp2)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.0745 (0.0096)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(mlp3)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.2340 (0.0378)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 0.2271 (0.0417)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.2203 (0.0391)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1705 (0.0247)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (mlp1, mlp2, mlp3))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1309 (0.0408)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (mlp1, mlp2, mlp3),\n",
    "                                                 meta_model = model_lgb)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09799704652961656\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09383280053978237\n"
     ]
    }
   ],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06716992176062296\n"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046845982186925345\n"
     ]
    }
   ],
   "source": [
    "mlp1.fit(train, y_train)\n",
    "mlp1_train_pred = mlp1.predict(train)\n",
    "mlp1_pred = np.expm1(mlp1.predict(test.values))\n",
    "print(rmsle(y_train, mlp1_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04984774414760795\n"
     ]
    }
   ],
   "source": [
    "mlp2.fit(train, y_train)\n",
    "mlp2_train_pred = mlp2.predict(train)\n",
    "mlp2_pred = np.expm1(mlp2.predict(test.values))\n",
    "print(rmsle(y_train, mlp2_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0490883842999656\n"
     ]
    }
   ],
   "source": [
    "mlp3.fit(train, y_train)\n",
    "mlp3_train_pred = mlp3.predict(train)\n",
    "mlp3_pred = np.expm1(mlp3.predict(test.values))\n",
    "print(rmsle(y_train, mlp3_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.04729598867740608\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "# print(rmsle(y_train,stacked_train_pred*0.90 + xgb_train_pred*0.05 + lgb_train_pred*0.05))\n",
    "print(rmsle(y_train,mlp1_train_pred*0.40 + mlp2_train_pred*0.30 + mlp3_train_pred*0.30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble = stacked_pred*0.90 + xgb_pred*0.05 + lgb_pred*0.05\n",
    "# ensemble = mlp1_pred*0.5 + mlp2_pred*0.5\n",
    "# ensemble = mlp2_pred\n",
    "ensemble = mlp1_pred*0.4 + mlp2_pred*0.3 + mlp3_pred*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_ID\n",
    "sub['time'] = ensemble\n",
    "sub.to_csv('time.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
